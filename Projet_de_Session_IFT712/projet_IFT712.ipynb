{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet de Session IFT712\n",
    "\n",
    "EDELINE Maxime - edem2901  \n",
    "L'HERMITE Valentin - lhev1601  \n",
    "IVANOV Nicolas - ivan2302  \n",
    "\n",
    "# Présentation\n",
    "\n",
    "Dans ce fichier, il est possible de d'éxécuter nos algorithmes afin d'analyser les résultats. Nous avons implémentés nos algorithmes de façon à ce qu'une seule ligne se voit modifié si on souhaite utilisé un classifieur différent.\n",
    "\n",
    "Nous allons travailler sur la base de données \"Leaf Classification\", fournie par Kaggle. On possède une base de données composé d'un ensemble de feuilles. Chaque feuille est caractérisé par 192 attributs. Le modèle doit être capable de déterminer l'espèce d'appartenance de la feuille parmi 99 espèces. Ainsi, l'objectif est d'entraîner le modèle pour qu'il détermine la classe d'appartenance d'une feuilles qu'on lui fourni parmi 99 classes.\n",
    "Pour cette exercice, nous avons implémenté ces algorithmes:\n",
    "* ADA Boost\n",
    "* Perceptron\n",
    "* Perceptron multicouches\n",
    "* Random Forest\n",
    "* Réseaux de neurone convolutifs\n",
    "* Machines à vecteurs de support\n",
    "\n",
    "\n",
    "Le référentiel git du projet est disponible ici:\n",
    "https://github.com/ValentinLH/Projet_de_Session_IFT712_Edeline_Ivanov_L-Hermite \n",
    "  \n",
    "  \n",
    "Additionnellement, nous avons également implémentés trois algorithmes de recherches d'hyperparamètres, à savoir:\n",
    "* Boostraping\n",
    "* Sous-échantillonnage croisée\n",
    "* Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par importer toutes les bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T21:34:30.182063400Z",
     "start_time": "2023-12-11T21:34:25.238228900Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Importation des designs patterns strategy\n",
    "from Modele.ClassifieurLineaire import *\n",
    "from Modele.RechercheHyperparameter.RechercheHyperparameter import *\n",
    "\n",
    "#Importation des algorithmes de classification\n",
    "from Modele.AdaBoost import *\n",
    "from Modele.Perceptron import *\n",
    "from Modele.RandomForest import *\n",
    "from Modele.SVM import *\n",
    "from Modele.Reseaux_de_Neurone import *\n",
    "from Modele.Convolutional_Neural_Network import *\n",
    "\n",
    "#Importation des algorithmes de recherche d'hyperparamètres\n",
    "from Modele.RechercheHyperparameter.SousEchantillonnageAleatoire import *\n",
    "from Modele.RechercheHyperparameter.ValidationCroisee import *\n",
    "from Modele.RechercheHyperparameter.BootstrapValidation import *\n",
    "\n",
    "#Importation de la classe gestionnaire des données\n",
    "from Modele.data import TrainData\n",
    "\n",
    "#Importation d'une librairie de normalisation des données\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va commencer par charger le jeu de données Leaf-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T21:34:31.290345100Z",
     "start_time": "2023-12-11T21:34:31.238555Z"
    }
   },
   "outputs": [],
   "source": [
    "#Répertoire du fichier train.csv\n",
    "repertoire = \"../leaf-classification/train.csv\"\n",
    "donnee_entrainement = TrainData(repertoire)\n",
    "\n",
    "# X = données\n",
    "# T = étiquettes de classes associées aux données\n",
    "X, T = donnee_entrainement.data, donnee_entrainement.leafClass\n",
    "\n",
    "#Normalisation des données\n",
    "echelle = StandardScaler()\n",
    "X = echelle.fit_transform(X)\n",
    "\n",
    "#Séparation des données en groupe d'entrainement et groupe de test selon la proportion de la base de test\n",
    "proportion_base_de_test = 0.2\n",
    "X_entrainement, X_test, T_entrainement, T_test = train_test_split(X, T, test_size=proportion_base_de_test, random_state=42)\n",
    "\n",
    "# Nous devons décommenter la partie suivante pour l'execution du CNN\n",
    "\"\"\"\n",
    "donnee_entrainement = TrainData(repertoire)\n",
    "\n",
    "chargement_entrainement = donnee_entrainement.read_image(repertoire_images=\"../leaf-classification/images\")\n",
    "donnee_entrainement.imshow()\n",
    "\n",
    "dataiter = torch.utils.data.DataLoader.__iter__((chargement_entrainement))\n",
    "images, etiquettes = dataiter.__next__()\n",
    "\n",
    "X_entrainement, X_test, T_entrainement, T_test = train_test_split(images, etiquettes, test_size=0.2, random_state=42)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisi ensuite l'algorithme de classifieur à utilisé et l'algorithme de recherche d'hyperparamètres, pour chacun des algorithmes ci-dessous, nous avons mis les hyperparamètres les plus optimaux que nous avons trouvé après avoir réalisé une recherche. Pour tester un algorithme, décommentez-le et commenté l'algorithme qui était utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T21:37:23.797128500Z",
     "start_time": "2023-12-11T21:37:23.792130400Z"
    }
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "#####               Ligne à modifier pour changer l'algorithme de classification                  ####\n",
    "######################################################################################################\n",
    "\n",
    "strategie_classifieur = Perceptron(learning_rate=0.112,max_iterations=500,penalty='l2')\n",
    "#strategie_classifieur = Reseaux_Neurones((64,64), learning_rate=\"adaptive\", learning_rate_init=0.25075, max_iter=600, activation=\"tanh\", solver=\"sgd\")\n",
    "#strategie_classifieur = AdaBoost(n_estimators=200, learning_rate=0.01, random_state=12, algorithm=\"SAMME.R\", max_depth_tree_classifieur=5)\n",
    "#strategie_classifieur = RandomForest(n_estimators=123, criterion=\"gini\")\n",
    "#strategie_classifieur = SVM(kernel='rbf', C=10.0)\n",
    "\n",
    "# Pour executer le CNN il faut aussi décommenter la partie traitement d'image au dessus\n",
    "#strategie_classifieur = Convolutional_Neural_Network(lr=0.001, epochs=15, batch_size=64, dropout=0.5)\n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "#####           Ligne à modifier pour changer l'algorithme de recherche d'hyperparamètres          ####\n",
    "#######################################################################################################\n",
    "strategie_recherche = ValidationCroisee(k=10)\n",
    "#strategie_recherche = SousEchantillonnage(k=10, proportion_validation=0.2)\n",
    "#strategie_recherche = BootstrapValidation(n_bootstrap=5,k_fold=5)\n",
    "\n",
    "\n",
    "#Construction du classifieur\n",
    "classifieur = ClassifieurLineaire(strategie_classifieur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-11T21:33:40.216652600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Recherche d'Hyperparametre\n",
    "recherche = RechercheHyperparameter(strategie_recherche)\n",
    "\n",
    "#Recherche des hyperparamètres\n",
    "recherche.recherche(classifieur, X_entrainement, T_entrainement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T21:38:00.146288100Z",
     "start_time": "2023-12-11T21:37:29.264617100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Entrainement du modèle\n",
    "classifieur.entrainement(X_entrainement, T_entrainement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T21:38:14.689765200Z",
     "start_time": "2023-12-11T21:38:02.346932Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prédiction et Affichage\n",
    "\n",
    "#Prediction sur la base de test\n",
    "predictions = classifieur.prediction(X_test) \n",
    "\n",
    "\n",
    "if type(strategie_classifieur) == Convolutional_Neural_Network and type(T_test) is not list:\n",
    "    _, y_test_pred = torch.max(T_test, 1)\n",
    "    T_test = y_test_pred.tolist()\n",
    "\n",
    "    _, y_train_pred = torch.max(T_entrainement, 1)\n",
    "    T_entrainement = y_train_pred.tolist()\n",
    "\n",
    "\n",
    "#Calcul de différentes metrique d'évaluation sur la base d'entrainement\n",
    "precision, rappel, f1, _ = classifieur.evaluer(X_entrainement, T_entrainement)\n",
    "print(f'Base D\\'entrainement : ')\n",
    "print(f'precision: {precision}')\n",
    "print(f'rappel: {rappel}')\n",
    "print(f'f1: {f1}')\n",
    "\n",
    "\n",
    "#Calcul de différentes metrique d'évaluation sur la base de test\n",
    "precision, rappel, f1, _ = classifieur.evaluer(X_test,T_test)\n",
    "print(f'\\nBase de Test : ')\n",
    "print(f'precision: {precision}')\n",
    "print(f'rappel: {rappel}')\n",
    "print(f'f1: {f1}')\n",
    "\n",
    "if type(strategie_classifieur) != Convolutional_Neural_Network:\n",
    "    #Affichage des résultats dans un espace à deux dimensions\n",
    "    classifieur.afficher_donnees_et_modele(X_entrainement, T_entrainement, X_test, T_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T21:29:48.351797400Z",
     "start_time": "2023-12-11T21:29:48.300033900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
