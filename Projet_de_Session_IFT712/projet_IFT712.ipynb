{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet de Session IFT712\n",
    "\n",
    "EDELINE Maxime - edem2901  \n",
    "L'HERMITE Valentin - lhev1601  \n",
    "IVANOV Nicolas - ivan2302  \n",
    "\n",
    "# Présentation\n",
    "\n",
    "Dans ce fichier, il est possible de d'éxécuter nos algorithmes afin d'analyser les résultats. Nous avons implémentés nos algorithmes de façon à ce qu'une seule ligne se voit modifié si on souhaite utilisé un classifieur différent.\n",
    "\n",
    "Nous allons travailler sur la base de données \"Leaf Classification\", fournie par Kaggle. On possède une base de données composé de 990 feuilles. Chaque feuille est caractérisé par 192 attributs. Le modèle doit être capable de déterminer l'espèce d'appartenance de la feuille parmi 99 espèces. Ainsi, l'objectif est d'entraîner le modèle pour qu'il détermine la classe d'appartenance d'une feuilles qu'on lui fourni parmi 99 classes.\n",
    "Pour cette exercice, nous avons implémenté ces algorithmes:\n",
    "* ADA Boost\n",
    "* Perceptron\n",
    "* Perceptron multicouches\n",
    "* Random Forest\n",
    "* Réseaux de neurone convolutifs\n",
    "* Machines à vecteurs de support\n",
    "\n",
    "  \n",
    "  \n",
    "Additionnellement, nous avons également implémentés trois algorithmes de recherches d'hyperparamètres, à savoir:\n",
    "* Boostraping\n",
    "* Sous-échantillonnage croisée\n",
    "* Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par importer toutes les bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T01:06:41.892086600Z",
     "start_time": "2023-12-08T01:06:39.270907500Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importation des designs patterns strategy\n",
    "from Modele.ClassifieurLineaire import *\n",
    "from Modele.RechercheHyperparameter.RechercheHyperparameter import *\n",
    "\n",
    "#Importation des algorithmes de classification\n",
    "from Modele.AdaBoost import *\n",
    "from Modele.Perceptron import *\n",
    "from Modele.RandomForest import *\n",
    "from Modele.RandomForestAvecACP import *\n",
    "from Modele.SVM import *\n",
    "\n",
    "from Modele.Reseaux_de_Neurone import *\n",
    "\n",
    "#Importation des algorithmes de recherche d'hyperparamètres\n",
    "from Modele.RechercheHyperparameter.SousEchantillonnageAleatoire import *\n",
    "from Modele.RechercheHyperparameter.ValidationCroisee import *\n",
    "\n",
    "#Importation de la classe gestionnaire des données\n",
    "from Modele.data import TrainData\n",
    "\n",
    "#Importation d'une librairie de normalisation des données\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va commencer par charger le jeu de données Leaf-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T01:06:41.959844800Z",
     "start_time": "2023-12-08T01:06:41.895565Z"
    }
   },
   "outputs": [],
   "source": [
    "#Répertoire du fichier train.csv\n",
    "repertoire = \"../leaf-classification/train.csv\"\n",
    "trainData = TrainData(repertoire)\n",
    "\n",
    "# X = données\n",
    "# T = étiquettes de classes associées aux données\n",
    "X, T = trainData.data, trainData.leafClass\n",
    "\n",
    "#Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#Séparation des données en groupe d'entrainement et groupe de test selon la proportion de la base de test\n",
    "proportion_base_de_test = 0.2\n",
    "X_train, X_test, T_train, T_test = train_test_split(X, T, test_size=proportion_base_de_test, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisi ensuite l'algorithme de classifieur à utilisé et l'lagorithme de recherche d'hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T01:06:41.964213600Z",
     "start_time": "2023-12-08T01:06:41.960868400Z"
    }
   },
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "#####               Ligne à modifier pour changer l'algorithme de classification                  ####\n",
    "######################################################################################################\n",
    "\n",
    "#strategie_classifieur = AdaBoost(n_estimators=200, learning_rate=0.01, random_state=0, algorithm=\"SAMME.R\", max_depth_tree_classifieur=3)\n",
    "#strategie_classifieur = RandomForest()\n",
    "strategie_classifieur = Reseaux_Neurones((64,64)) \n",
    "\n",
    "#######################################################################################################\n",
    "#####           Ligne à modifier pour changer l'algorithme de recherche d'hyperparamètres          ####\n",
    "#######################################################################################################\n",
    "strategie_recherche = ValidationCroisee(k = 10)\n",
    "\n",
    "#Construction du classifieur\n",
    "classifieur = ClassifieurLineaire(strategie_classifieur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-08T01:06:41.966212300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Recherche d'Hyperparametre\n",
    "recherche = RechercheHyperparameter(strategie_recherche)\n",
    "\n",
    "#Recherche des hyperparamètres\n",
    "recherche.recherche(classifieur, X, T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Entrainement du modèle\n",
    "classifieur.entrainement(X_train, T_train)\n",
    "\n",
    "#Prediction sur la base de test\n",
    "predictions = classifieur.prediction(X_test) \n",
    "\n",
    "#Calcul de différentes metrique d'évaluation sur la base d'entrainement\n",
    "precision, rappel, f1, _ = classifieur.evaluer(X_train, T_train)\n",
    "print(f'Base D\\'entrainement : ')\n",
    "print(f'precision: {precision}')\n",
    "print(f'rappel: {rappel}')\n",
    "print(f'f1: {f1}')\n",
    "\n",
    "\n",
    "#Calcul de différentes metrique d'évaluation sur la base de test\n",
    "precision, rappel, f1, _ = classifieur.evaluer(X_test,T_test)\n",
    "print(f'\\nBase de Test : ')\n",
    "print(f'precision: {precision}')\n",
    "print(f'rappel: {rappel}')\n",
    "print(f'f1: {f1}')\n",
    "\n",
    "#Affichage des résultats dans un espace à deux dimensions\n",
    "classifieur.afficher_donnees_et_modele(X_train, T_train, X_test, T_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
